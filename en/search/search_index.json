{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The solution Real-time Fraud Detection with Graph Neural Network on DGL is an end-to-end solution for real-time fraud detection which leverages graph database Amazon Neptune , Amazon SageMaker and Deep Graph Library (DGL) to construct a heterogeneous graph from tabular data and train a Graph Neural Network(GNN) model to detect fraudulent transactions in the IEEE-CIS dataset . The solutions consists of below major features: uses the Deep Graph Library (DGL) to build machine learning model. DGL is an advanced open source framework designed for graph neural network has a complete workflow pipeline for model training and updating, including data ingesting, data processing, model training, model rolling update leverages Graph database to do real-time fraud detection This implementation guide discusses architectural considerations and configuration steps for deploying the Real-time Fraud Detection with Graph Neural Network on DGL solution in the Amazon Web Services (AWS) Cloud. It includes a link to an AWS CloudFormation template that launches and configures the AWS services required to deploy this solution using AWS best practices for security and availability. The guide is intended for IT architects, developers, DevOps and data analysts who have practical experience architecting in the AWS Cloud and data scientists and algorithm engineers with few AWS knowledge.","title":"Welcome"},{"location":"architecture/","text":"Deploying this solution with the default parameters builds the following environment in the AWS Cloud. Figure 1\uff1aarchitecture of construct graph data, model training and model deployment Figure 2\uff1aarchitecture of real-time fraud detection and business monitor system This solution deploys five AWS CloudFormation templates in your AWS account and sets up the following: The first AWS CloudFormation template realtime-fraud-detection-with-gnn-on-dgl creates: an Amazon Virtual Private Cloud (Amazon VPC) running a NAT gateway , and an internet gateway . a Graph database Amazon Neptune cluster with one read replica\uff0cthe default instance size is db.r5.xlarge . an Amazon SQS message queue\u3002 The second CloudFormation template starting with realtime-fraud-detection-with-gnn-on-dgl-trainingNestedStack creates: an AWS Step Functions workflow pipeline trains the model from tabular finance trasaction dataset, then deploy the online infernce endpoint. AWS Glue data catalog and ETL job are used transforming the original tabular data to graph structure data. Amazon ECS on AWS Fargate import the graph data into graph database Amazon Neptune. Amazon SageMaker trains model and deploy the online inference endpoint. AWS Lambda functions implement raw data ingesting, post-processing after model training and other glue work. The third CloudFormation template starting with realtime-fraud-detection-with-gnn-on-dgl-inferenceNestedStack creates: AWS Lambda function implements the real-time fraud detection endpoint. The fourth CloudFormation tempalte starting with realtime-fraud-detection-with-gnn-on-dgl-dashboardNestedStack creates: Amazon DocumentDB stores the transactions and their properties, its credential is saved in AWS Secrets Manager . AWS Lambda function receives the real-time online trasactions and stores in DocumentDB. the business dashboard website hosting in Amazon S3 and distributed by Amazon CloudFront . the backend of business dashboard consits of Amazon API Gateway and AWS AppSync . The fifth CloudFormation template starting with realtime-fraud-detection-with-gnn-on-dgl-DashboardDatabaseRotation creates: AWS Lambda function will periodically rotate the user credential of DocumentDB stored in Secrets Manager. For redundancy, the Amazon VPCs are created with subnets in two Availability Zones (AZs) for high availability. The NAT gateway, Amazon Neptune, Amazon DocumentDB, AWS Glue and other AWS resources are deployed across these two AZs. NOTE : AWS CloudFormation resources are created from AWS Cloud Development Kit (CDK) (AWS CDK) constructs.","title":"Architecture overview"},{"location":"components/","text":"the pipeline of data processing, model training and deployment The solution uses AWS Step Functions workflow orchestrate the pipeline from raw IEEE-CIS dataset , graph data processing, training GNN model and inference endpoint deployment. Below is the detail for each workflow step, Use AWS Lambda function downloads dataset to Amazon S3 bucket Execute AWS Glue crawler to build Glue Data Catalog from dataset Execute AWS Glue ETL job processing the raw data, converting the tabular data to graph structure data, then write to S3 bucket Use Amazon SageMaker trains the GNN model on DGL After training the model, loading graph structure data into graph database Neptune Amazon Neptune Package the custom inference code with model Use Amazon SageMaker to create model, configure endpoint configuration and deploying inference endpoint real-time fraud detection and business monitor system real-time fraud detection The solution follows below steps for implementing real-time fraud detection , Process the online transaction data as the graph structure data Insert the graph data(vertices, edges and relationships) into graph database Neptune Query the sub-graph of current transaction vertice and its 2nd connected vertices Send the data of sub-graph to inference endpoint to get the possibility of fraudulent of the transaction. Then publish the transaction and its fraudulent possibility to Amazon SQS queue business monitor system The solution uses below services consisting of the monitor system of fraudulent transactions, Use AWS Lambda function to process the online transaction in SQS queue, then store them into Amazon DocumentDB Provide the transaction stats interface via AWS AppSync The web app of monitor system is deployed on Amazon S3 , and it's distributed by CDN Amazon CloudFront Mock up the online transactions via AWS Step Functions , which uses test data in IEEE-CIS dataset requesting the API of fraud detection of transactions Amazon API Gateway provides the authentication for AppSync interface and trigger the simulation of online transactions","title":"Components"},{"location":"components/#the-pipeline-of-data-processing-model-training-and-deployment","text":"The solution uses AWS Step Functions workflow orchestrate the pipeline from raw IEEE-CIS dataset , graph data processing, training GNN model and inference endpoint deployment. Below is the detail for each workflow step, Use AWS Lambda function downloads dataset to Amazon S3 bucket Execute AWS Glue crawler to build Glue Data Catalog from dataset Execute AWS Glue ETL job processing the raw data, converting the tabular data to graph structure data, then write to S3 bucket Use Amazon SageMaker trains the GNN model on DGL After training the model, loading graph structure data into graph database Neptune Amazon Neptune Package the custom inference code with model Use Amazon SageMaker to create model, configure endpoint configuration and deploying inference endpoint","title":"the pipeline of data processing, model training and deployment"},{"location":"components/#real-time-fraud-detection-and-business-monitor-system","text":"","title":"real-time fraud detection and business monitor system"},{"location":"components/#real-time-fraud-detection","text":"The solution follows below steps for implementing real-time fraud detection , Process the online transaction data as the graph structure data Insert the graph data(vertices, edges and relationships) into graph database Neptune Query the sub-graph of current transaction vertice and its 2nd connected vertices Send the data of sub-graph to inference endpoint to get the possibility of fraudulent of the transaction. Then publish the transaction and its fraudulent possibility to Amazon SQS queue","title":"real-time fraud detection"},{"location":"components/#business-monitor-system","text":"The solution uses below services consisting of the monitor system of fraudulent transactions, Use AWS Lambda function to process the online transaction in SQS queue, then store them into Amazon DocumentDB Provide the transaction stats interface via AWS AppSync The web app of monitor system is deployed on Amazon S3 , and it's distributed by CDN Amazon CloudFront Mock up the online transactions via AWS Step Functions , which uses test data in IEEE-CIS dataset requesting the API of fraud detection of transactions Amazon API Gateway provides the authentication for AppSync interface and trigger the simulation of online transactions","title":"business monitor system"},{"location":"data-scientist/","text":"There are Jupyter notebooks for data engineering/scientist playing with the data featuring, model training and deploying inference endpoint without deploying this solution.","title":"Data scientist"},{"location":"deployment/","text":"Before you launch the solution, review the supported region, architecture and components in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account. Time to deploy : Approximately 30 minutes Deployment overview The procedure of deploying this architecture on AWS consists of the following steps. For detailed instructions, follow the links for each step. Step 1. Launch the stack Launch the AWS CloudFormation template into your AWS account. Review the template parameters, and adjust if necessary. Step 2. Launch the pipeline of data processing, model training and deploying Start the pipeline of model training and deployment. Step 3. simulate the online transactions Get the visualization stats result of real-time fraud detection. Step 1. Launch the stack This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Sign in to the AWS Management Console and use one of the buttons below to launch the AWS CloudFormation template. Launch solution Launch solution with custom domain of business system Optionally, you can download the template as a starting point for your own implementation. The template launches in the US East (N. Virginia) Region by default. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a valid and account level unique name to your solution stack. This ensures all the resources in the stack remain under the maximum length allowed by CloudFormation. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following default values. Parameter Default Description NeptuneInstaneType db.r5.xlarge Specify the instance size of Neptune, the available value contains, db.r5.xlarge\u3001db.r5.2xlarge\u3001db.r5.4xlarge\u3001db.r5.8xlarge\u3001db.r5.12xlarge Below parameters only are required when deploying the solution with custom domain name of business system. Parameter Default Description DashboardDomain Special the custom domain of business system deployed by solution. Note : it must be the sub-domain of the domain given by below public zone of R53 Route53HostedZoneId select the public hosted zone of Route 53 in account Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately thirty minutes. Step 2. Launch the pipeline of data processing, model training and deploying Using AWS Step Functions workflow deployed by the solution processes the transaction data, trains the GNN model and deploys the inference endpoint. Sign in to the AWS Management Console. Go to AWS Step Functions service, choose State machines \u3002 Choose the name of state machine starting with ModelTrainingPipeline , choose Start execution , use the default input to start execution. You can view the execution status of details of execution. You should receive a Succeeded status in approximately three hours. Note \uff1a The complete execution time of pipeline depends on the instance size of Amazon Neptune, choose db.r5.8xlarge or above size\uff0cthe execution is approximately two hours. Step 3. simulate the online transactions Access the business system deployed by the solution. The url of business system can be found in the output of AWS CloudFormation stack. Go to AWS CloudFormation console, choose the stack name starting with realtime-fraud-detection-with-gnn-on-dgl or the custom name specified in deployment time, choose Outputs , find the key DashboardWebsiteUrl , its value is the url of business system that is either the CloudFront domain name or custom domain name. Choose SIMULATE DATA button, input the valid parameters of simulation, including the duration(seconds) of simulation, concurrent number and the interval(seconds) between two simuated requests. If using the default parameters, it will use ten concurrent programs to simulate the online transactions five minutes with three seconds interval between two requests. After setting the parameters, choose SIMULATE button to start the simulation. It might cost about two minutes to prepare transactions data in simulation backend program, after approximately three minutes, the monitor system will receive the stats of online transactions, including the number of transactions requesting in system, the number of fraudulent transactions in latest five minutes.","title":"Deployment"},{"location":"deployment/#deployment-overview","text":"The procedure of deploying this architecture on AWS consists of the following steps. For detailed instructions, follow the links for each step. Step 1. Launch the stack Launch the AWS CloudFormation template into your AWS account. Review the template parameters, and adjust if necessary. Step 2. Launch the pipeline of data processing, model training and deploying Start the pipeline of model training and deployment. Step 3. simulate the online transactions Get the visualization stats result of real-time fraud detection.","title":"Deployment overview"},{"location":"deployment/#step-1-launch-the-stack","text":"This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Sign in to the AWS Management Console and use one of the buttons below to launch the AWS CloudFormation template. Launch solution Launch solution with custom domain of business system Optionally, you can download the template as a starting point for your own implementation. The template launches in the US East (N. Virginia) Region by default. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a valid and account level unique name to your solution stack. This ensures all the resources in the stack remain under the maximum length allowed by CloudFormation. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following default values. Parameter Default Description NeptuneInstaneType db.r5.xlarge Specify the instance size of Neptune, the available value contains, db.r5.xlarge\u3001db.r5.2xlarge\u3001db.r5.4xlarge\u3001db.r5.8xlarge\u3001db.r5.12xlarge Below parameters only are required when deploying the solution with custom domain name of business system. Parameter Default Description DashboardDomain Special the custom domain of business system deployed by solution. Note : it must be the sub-domain of the domain given by below public zone of R53 Route53HostedZoneId select the public hosted zone of Route 53 in account Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately thirty minutes.","title":"Step 1. Launch the stack"},{"location":"deployment/#step-2-launch-the-pipeline-of-data-processing-model-training-and-deploying","text":"Using AWS Step Functions workflow deployed by the solution processes the transaction data, trains the GNN model and deploys the inference endpoint. Sign in to the AWS Management Console. Go to AWS Step Functions service, choose State machines \u3002 Choose the name of state machine starting with ModelTrainingPipeline , choose Start execution , use the default input to start execution. You can view the execution status of details of execution. You should receive a Succeeded status in approximately three hours. Note \uff1a The complete execution time of pipeline depends on the instance size of Amazon Neptune, choose db.r5.8xlarge or above size\uff0cthe execution is approximately two hours.","title":"Step 2. Launch the pipeline of data processing, model training and deploying"},{"location":"deployment/#step-3-simulate-the-online-transactions","text":"Access the business system deployed by the solution. The url of business system can be found in the output of AWS CloudFormation stack. Go to AWS CloudFormation console, choose the stack name starting with realtime-fraud-detection-with-gnn-on-dgl or the custom name specified in deployment time, choose Outputs , find the key DashboardWebsiteUrl , its value is the url of business system that is either the CloudFront domain name or custom domain name. Choose SIMULATE DATA button, input the valid parameters of simulation, including the duration(seconds) of simulation, concurrent number and the interval(seconds) between two simuated requests. If using the default parameters, it will use ten concurrent programs to simulate the online transactions five minutes with three seconds interval between two requests. After setting the parameters, choose SIMULATE button to start the simulation. It might cost about two minutes to prepare transactions data in simulation backend program, after approximately three minutes, the monitor system will receive the stats of online transactions, including the number of transactions requesting in system, the number of fraudulent transactions in latest five minutes.","title":"Step 3. simulate the online transactions"},{"location":"regions/","text":"Supported AWS regions The solution is using graph database Amazon Neptune for real-time fraud detection and Amazon DocumentDB for dashboard. Due to the availability of those services, the solution supports to be deployed to below regions, US East (N. Virginia): us-east-1 US East (Ohio): us-east-2 US West (Oregon): us-west-2 Canada (Central): ca-central-1 South America (S\u00e3o Paulo): sa-east-1 Europe (Ireland): eu-west-1 Europe (London): eu-west-2 Europe (Paris): eu-west-3 Europe (Frankfurt): eu-central-1 Asia Pacific (Tokyo): ap-northeast-1 Asia Pacific (Seoul): ap-northeast-2 Asia Pacific (Singapore): ap-southeast-1 Asia Pacific (Sydney): ap-southeast-2 Asia Pacific (Mumbai): ap-south-1 China (Beijing) Region operated by Sinnet: cn-north-1 China (Ningxia) Region operated by NWCD: cn-northwest-1","title":"Supported regions"},{"location":"regions/#supported-aws-regions","text":"The solution is using graph database Amazon Neptune for real-time fraud detection and Amazon DocumentDB for dashboard. Due to the availability of those services, the solution supports to be deployed to below regions, US East (N. Virginia): us-east-1 US East (Ohio): us-east-2 US West (Oregon): us-west-2 Canada (Central): ca-central-1 South America (S\u00e3o Paulo): sa-east-1 Europe (Ireland): eu-west-1 Europe (London): eu-west-2 Europe (Paris): eu-west-3 Europe (Frankfurt): eu-central-1 Asia Pacific (Tokyo): ap-northeast-1 Asia Pacific (Seoul): ap-northeast-2 Asia Pacific (Singapore): ap-southeast-1 Asia Pacific (Sydney): ap-southeast-2 Asia Pacific (Mumbai): ap-south-1 China (Beijing) Region operated by Sinnet: cn-north-1 China (Ningxia) Region operated by NWCD: cn-northwest-1","title":"Supported AWS regions"},{"location":"uninstall/","text":"To uninstall the Real-time Fraud Detection with Graph Neural Network on DGL solution, delete the AWS CloudFormation stack. This will delete all the resources created by the template except the S3 buckets starting with realtime-fraud-detection-frauddetectiondatabucket and realtime-fraud-detection-bucketaccesslog . These two buckets will be retained when the solution stack is deleted in order to help prevent accidental data loss. You can use either the AWS Management Console or the AWS Command Line Interface (AWS CLI) to empty, then delete those S3 buckets after deleting the CloudFormation stack. Using the AWS Management Console Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack, the default is realtime-fraud-detection-with-gnn-on-dgl . Choose Delete . Using AWS Command Line Interface Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region> Deleting the Amazon S3 buckets Real-time Fraud Detection with Graph Neural Network on DGL solution creates two S3 buckets that are not automatically deleted. To delete these buckets, use the steps below. Sign in to the Amazon S3 console. Select the bucket name starting with realtime-fraud-detection-frauddetectiondatabucket . Choose Empty . Choose Delete . Select the bucket name starting with realtime-fraud-detection-bucketaccesslog . Choose Empty . Choose Delete . To delete the S3 bucket using AWS CLI, run the following command: aws s3 rb s3://<bucket-name> --force Deleting the endpoint of Amazon SageMaker An endpoint of Amazon SageMkaker would be created after you train the model. You can remove the endpoint to avoid the recurred cost. Sign in to the Amazon SageMaker console. Select the Inference - Endpoints from left sidebar. Choose the endpoint with name frauddetection . Choose Actions - Delete .","title":"Uninstall the solution"},{"location":"uninstall/#using-the-aws-management-console","text":"Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack, the default is realtime-fraud-detection-with-gnn-on-dgl . Choose Delete .","title":"Using the AWS Management Console"},{"location":"uninstall/#using-aws-command-line-interface","text":"Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region>","title":"Using AWS Command Line Interface"},{"location":"uninstall/#deleting-the-amazon-s3-buckets","text":"Real-time Fraud Detection with Graph Neural Network on DGL solution creates two S3 buckets that are not automatically deleted. To delete these buckets, use the steps below. Sign in to the Amazon S3 console. Select the bucket name starting with realtime-fraud-detection-frauddetectiondatabucket . Choose Empty . Choose Delete . Select the bucket name starting with realtime-fraud-detection-bucketaccesslog . Choose Empty . Choose Delete . To delete the S3 bucket using AWS CLI, run the following command: aws s3 rb s3://<bucket-name> --force","title":"Deleting the Amazon S3 buckets"},{"location":"uninstall/#deleting-the-endpoint-of-amazon-sagemaker","text":"An endpoint of Amazon SageMkaker would be created after you train the model. You can remove the endpoint to avoid the recurred cost. Sign in to the Amazon SageMaker console. Select the Inference - Endpoints from left sidebar. Choose the endpoint with name frauddetection . Choose Actions - Delete .","title":"Deleting the endpoint of Amazon SageMaker"}]}